= Deploy example to GKE cluster
:toc:
:toc-title: ON THIS PAGE
:toclevels: 2

include::ROOT:partial$include.adoc[]

Once the application is built you need to publish the docker image to some registry that stores, manages and secures your application image. In this example we will use the GCloud registry `eu.gcr.io`.

Follow these steps to complete the process of publishing:

* Set up the target environment of publishing in your local build process. Create a file named `target-env.sbt` in the root of your project folder (the same level where you have `build.sbt`). The file needs to have the following 2 lines:

```
ThisBuild / cloudflowDockerRegistry := Some("eu.gcr.io")
ThisBuild / cloudflowDockerRepository := Some("<gcloud project id>")
```

Here `project id` refers to the _ID_ of your Google Cloud Platform project. This can be found on the project page of your Google Cloud Platform.

* Publish the docker image of your project to the above registry. This has 3 steps:
 * First make sure that you have access to the cluster `gcloud container clusters get-credentials <cluster-name>`
 * And that you have access to the Google docker registry `gcloud auth configure-docker`
 * Then publish `sbt buildAndPublish`

Once the image is successfully published, you will see something like the following as output of `buildAndPublish` in your console:

```
[info] 2-89ce8a7: digest: sha256:ee496e8cf3a3d9ab71c3ef4a4929ed8eeb6129845f981c33005942314ad30f18 size: 6804
[info]  
[info] Successfully built and published the following Cloudflow application image:
[info]  
[info]   eu.gcr.io/<gcloud project id>/sensor-data:2-89ce8a7
[info]  
[info] You can deploy the application to a Kubernetes cluster using any of the the following commands:
[info]  
[info]   kubectl-cloudflow deploy eu.gcr.io/<gcloud project id>/sensor-data:2-89ce8a7
```

So now the image is available in the registry for deployment. We will next use Cloudflow CLI to deploy the application to the cluster.

== Deploy Application to the Cluster

This is quite straightforward and the output of `buildAndPublish` actually tells you what command to run for deployment. In addition you need to supply the credentials along with the CLI.

```
$ kubectl-cloudflow deploy -u oauth2accesstoken eu.gcr.io/<gcloud project id>/sensor-data:2-89ce8a7 -p "$(gcloud auth print-access-token)"
```

If the command goes through you will see the following output:

```
[Done] Deployment of application `sensor-data` has started.
```

Once all streamlets are up in their pods, you can see them running using the following command:

```
$ kubectl get pods -n sensor-data
NAME                                          READY   STATUS    RESTARTS   AGE
sensor-data-http-ingress-fd9cdb66f-jbsrm      1/1     Running   0          3m1s
sensor-data-invalid-logger-549d687d89-m64l7   1/1     Running   0          3m1s
sensor-data-metrics-6c47bfb489-xd644          1/1     Running   0          3m1s
sensor-data-valid-logger-76884bb775-86pwh     1/1     Running   0          3m1s
sensor-data-validation-7dd858b6c5-lcp2n       1/1     Running   0          3m1s
```

Note that all streamlets run in a namespace that matches the name of the application.

**Congratulations!** You have deployed and started your first Cloudflow application.

== Sending data to the application

To send data to the application, we create a route from the outside of the cluster. 

There are two alternatives for creating this route; one is a localhost port forward, the other is an ingress. In this example, we use an ingress.

The [Kubernetes service]https://kubernetes.io/docs/concepts/services-networking/service/ created by the Cloudflow operator during application deployment, exposes the application inside the cluster. The ingress exposes the application, via the service, to the outside of the cluster. 

A general overview of ingresses and alternatives to ingresses are available xref:ingress-setup.adoc[here].

To create the ingress, run the following script:

[source, bash]
----
cat <<EOF | kubectl apply -f - 
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: sensor-data-http-ingress
  namespace: sensor-data-scala
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
    rules:
    - http:
        paths:
        - path: /sensor-data
          backend:
            servicePort: 3003
            serviceName: sensor-data-scala-http-ingress-service
EOF
----

The ingress controller updates the ingress resource once an address allocated has been allocated. 

[source, bash]
----
> kubectl get ingress -sensor-data-scala
NAME                       HOSTS   ADDRESS           PORTS     AGE
sensor-data-http-ingress   *       35.195.246.199    80        59s
----

We now have an address of the ingress and can continue to send data to the application using the example test data.

In this case, we use the https://httpie.org[Httpie] CLI tool to post data to the application.

[source, bash]
----
http POST http://35.195.246.199/sensor-data < test-data/04-moderate-breeze.json
HTTP/1.1 202 Accepted
Connection: keep-alive
Content-Length: 88
Content-Type: text/plain; charset=UTF-8
Date: Thu, 13 Feb 2020 09:20:38 GMT
Server: nginx/1.17.7

The request has been accepted for processing, but the processing has not been completed.
----

As seen above, the request now has been accepted for processing by the streamlet.
